{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data, Datasets & Utils\n",
    "import pandas as pd\n",
    "from pandas.plotting import scatter_matrix\n",
    "import pprint\n",
    "import numpy as np\n",
    "from time import time\n",
    "from numpy import log2 as log\n",
    "\n",
    "# Validation methods\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Metrics\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Classifiers\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "\n",
    "\n",
    "# Hyper-parameter optimisation\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# Feature selection & feature engineering\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Stats\n",
    "from scipy.stats import randint as sp_randint\n",
    "from scipy.stats import pearsonr\n",
    "from scipy.stats import spearmanr\n",
    "from scipy.stats import shapiro     # Shapiro Wilk\n",
    "from scipy.stats import normaltest  # D’Agostino’s K^2\n",
    "from scipy.stats import anderson    # Anderson-Darling\n",
    "from scipy.stats import ttest_ind    # independent student t-test; assumes normality\n",
    "from scipy.stats import mannwhitneyu # non-parametric; doesn't assume normality\n",
    "\n",
    "# Visualisation\n",
    "import matplotlib.pyplot as plot \n",
    "import seaborn as sns\n",
    "from IPython.display import SVG\n",
    "from graphviz import Source\n",
    "from IPython.display import display\n",
    "from sklearn.tree import export_graphviz\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape:\n",
      "\n",
      " (569, 32)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 569 entries, 0 to 568\n",
      "Data columns (total 32 columns):\n",
      " #   Column                      Non-Null Count  Dtype  \n",
      "---  ------                      --------------  -----  \n",
      " 0   ID                          568 non-null    float64\n",
      " 1   Radius (Mean)               550 non-null    float64\n",
      " 2   Texture (Mean)              568 non-null    float64\n",
      " 3   Perimeter (Mean)            567 non-null    float64\n",
      " 4   Area (Mean)                 566 non-null    float64\n",
      " 5   Smoothness (Mean)           567 non-null    float64\n",
      " 6   Compactness (Mean)          566 non-null    float64\n",
      " 7   Concavity (Mean)            569 non-null    float64\n",
      " 8   Concave Points (Mean)       569 non-null    float64\n",
      " 9   Symmetry (Mean)             566 non-null    float64\n",
      " 10  Fractal Dimension (Mean)    567 non-null    float64\n",
      " 11  Radius (Error)              551 non-null    float64\n",
      " 12   Texture (Error)            567 non-null    float64\n",
      " 13   Perimeter (Error)          568 non-null    float64\n",
      " 14   Area (Error)               567 non-null    float64\n",
      " 15   Smoothness (Error)         566 non-null    float64\n",
      " 16   Compactness (Error)        568 non-null    float64\n",
      " 17   Concavity (Error)          568 non-null    float64\n",
      " 18   Concave Points (Error)     567 non-null    float64\n",
      " 19   Symmetry (Error)           568 non-null    float64\n",
      " 20   Fractal Dimension (Error)  567 non-null    float64\n",
      " 21   Radius (Worst)             551 non-null    float64\n",
      " 22   Texture (Worst)            566 non-null    float64\n",
      " 23   Perimeter (Worst)          567 non-null    float64\n",
      " 24   Area (Worst)               566 non-null    float64\n",
      " 25   Smoothness (Worst)         569 non-null    float64\n",
      " 26   Compactness (Worst)        565 non-null    float64\n",
      " 27   Concavity (Worst)          567 non-null    float64\n",
      " 28  Concave Points (Worst)      566 non-null    float64\n",
      " 29  Symmetry (Worst)            566 non-null    float64\n",
      " 30  Fractal Dimension (Worst)   565 non-null    float64\n",
      " 31  Diagnosis                   569 non-null    object \n",
      "dtypes: float64(31), object(1)\n",
      "memory usage: 142.4+ KB\n",
      "None\n",
      "\n",
      "Unique Values in 'Diagnosis' ['M', 'B']\n"
     ]
    }
   ],
   "source": [
    "#Reading data set file\n",
    "\n",
    "df = pd.read_csv('data/breast-cancer.csv')\n",
    "print(\"Shape:\\n\\n\",df.shape) #tells us how many rows and columns the data structer has got\n",
    "print(df.info())\n",
    "df.head()\n",
    "print(\"\\nUnique Values in 'Diagnosis'\", list(df.Diagnosis.unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "df = df.fillna(df.mean())\n",
    "df.isnull().sum()\n",
    "\n",
    "df['Diagnosis'].replace('M', 1,inplace=True)\n",
    "df['Diagnosis'].replace('B', 0,inplace=True)\n",
    "\n",
    "names = df.columns\n",
    "scaler = MinMaxScaler() \n",
    "df = scaler.fit_transform(df) \n",
    "df = pd.DataFrame(df, columns=names)\n",
    "\n",
    "# Splits the Pandas DataFrame into a feature matrix (X) and class/label vector (y)\n",
    "X = df.iloc[:,1:31]\n",
    "y = df['Diagnosis']\n",
    "\n",
    "# Transform class labels to numeric labels\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(y)\n",
    "y = le.transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Nearest Neigbors\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'estimator': (KNeighborsClassifier(),\n",
      "               KNeighborsClassifier(),\n",
      "               KNeighborsClassifier(),\n",
      "               KNeighborsClassifier(),\n",
      "               KNeighborsClassifier(),\n",
      "               KNeighborsClassifier(),\n",
      "               KNeighborsClassifier(),\n",
      "               KNeighborsClassifier(),\n",
      "               KNeighborsClassifier(),\n",
      "               KNeighborsClassifier(),\n",
      "               KNeighborsClassifier(),\n",
      "               KNeighborsClassifier()),\n",
      " 'fit_time': array([0.00398803, 0.0039885 , 0.0039897 , 0.00398946, 0.00399041,\n",
      "       0.00299191, 0.00398946, 0.0039885 , 0.00398898, 0.00398898,\n",
      "       0.0039885 , 0.00398827]),\n",
      " 'score_time': array([0.00797749, 0.00598383, 0.00698137, 0.00598407, 0.00698256,\n",
      "       0.00698137, 0.00598359, 0.00598478, 0.00598431, 0.00598478,\n",
      "       0.00598526, 0.00598454]),\n",
      " 'test_score': array([0.94736842, 0.96842105, 0.97894737, 0.95789474, 0.98947368,\n",
      "       0.9787234 , 0.95789474, 0.97894737, 0.96842105, 0.97894737,\n",
      "       0.95789474, 0.96808511]),\n",
      " 'train_score': array([0.98101266, 0.97890295, 0.97679325, 0.97468354, 0.96835443,\n",
      "       0.97684211, 0.97679325, 0.97257384, 0.98101266, 0.97257384,\n",
      "       0.97468354, 0.97263158])}\n",
      "\n",
      "Accuracy (Training): 0.98 (+/- 0.01)\n",
      "Accuracy (Testing):  0.97 (+/- 0.02)\n",
      "[[351   7]\n",
      " [ 14 197]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.98      0.97       358\n",
      "           1       0.97      0.93      0.95       211\n",
      "\n",
      "    accuracy                           0.96       569\n",
      "   macro avg       0.96      0.96      0.96       569\n",
      "weighted avg       0.96      0.96      0.96       569\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#KNN Model 1\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold #this seems pretty good one\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "# Creating the model, training and testing it\n",
    "k = 5\n",
    "model = KNeighborsClassifier(n_neighbors=k, p=2, metric='minkowski')\n",
    "\n",
    "#random_state = 12883823 36851234\n",
    "rkf = RepeatedStratifiedKFold(n_splits=6, n_repeats=2,\n",
    "      random_state=4)\n",
    "scores = cross_validate(model, X, y, cv=rkf, return_train_score=True, return_estimator=True)\n",
    "y_pred = cross_val_predict(model, X, y, cv=6)\n",
    "\n",
    "# Printing results\n",
    "pprint.pprint(scores)\n",
    "print()\n",
    "\n",
    "print(\"Accuracy (Training): %0.2f (+/- %0.2f)\" % (scores['train_score'].mean(), scores['train_score'].std() * 2))\n",
    "print(\"Accuracy (Testing):  %0.2f (+/- %0.2f)\" % (scores['test_score'].mean(), scores['test_score'].std() * 2))\n",
    "print(confusion_matrix(y, y_pred))\n",
    "report = classification_report(y, y_pred)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'estimator': (KNeighborsClassifier(metric='manhattan', weights='distance'),\n",
      "               KNeighborsClassifier(metric='manhattan', weights='distance'),\n",
      "               KNeighborsClassifier(metric='manhattan', weights='distance'),\n",
      "               KNeighborsClassifier(metric='manhattan', weights='distance'),\n",
      "               KNeighborsClassifier(metric='manhattan', weights='distance'),\n",
      "               KNeighborsClassifier(metric='manhattan', weights='distance'),\n",
      "               KNeighborsClassifier(metric='manhattan', weights='distance'),\n",
      "               KNeighborsClassifier(metric='manhattan', weights='distance')),\n",
      " 'fit_time': array([0.00299144, 0.00398445, 0.00398922, 0.00398946, 0.00299168,\n",
      "       0.00398946, 0.00299239, 0.00398946]),\n",
      " 'score_time': array([0.00498629, 0.00498462, 0.00598431, 0.00498748, 0.00498676,\n",
      "       0.00398898, 0.00498629, 0.00398922]),\n",
      " 'test_score': array([0.99300699, 0.96478873, 0.97183099, 0.94366197, 0.95104895,\n",
      "       0.98591549, 0.95774648, 0.96478873]),\n",
      " 'train_score': array([1., 1., 1., 1., 1., 1., 1., 1.])}\n",
      "\n",
      "Accuracy (Training): 1.00 (+/- 0.00)\n",
      "Accuracy (Testing):  0.97 (+/- 0.03)\n",
      "[[355   3]\n",
      " [ 15 196]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.99      0.98       358\n",
      "           1       0.98      0.93      0.96       211\n",
      "\n",
      "    accuracy                           0.97       569\n",
      "   macro avg       0.97      0.96      0.97       569\n",
      "weighted avg       0.97      0.97      0.97       569\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#KNN model 2\n",
    "# Creating the model, training and testing it\n",
    "k = 5\n",
    "model1 = KNeighborsClassifier(n_neighbors=k, weights='distance', metric='manhattan')\n",
    "\n",
    "#random_state = 12883823 36851234 random_state=12883823\n",
    "rkf = RepeatedStratifiedKFold(n_splits=4, n_repeats=2)\n",
    "scores = cross_validate(model1, X, y, cv=rkf, return_train_score=True, return_estimator=True)\n",
    "\n",
    "y_pred = cross_val_predict(model1, X, y, cv=6)\n",
    "# Printing results\n",
    "pprint.pprint(scores)\n",
    "print()\n",
    "#print(X_test)\n",
    "print(\"Accuracy (Training): %0.2f (+/- %0.2f)\" % (scores['train_score'].mean(), scores['train_score'].std() * 2))\n",
    "print(\"Accuracy (Testing):  %0.2f (+/- %0.2f)\" % (scores['test_score'].mean(), scores['test_score'].std() * 2))\n",
    "print(confusion_matrix(y, y_pred))\n",
    "report = classification_report(y, y_pred)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Decision Trees with hyper parameter optimization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'estimator': (DecisionTreeClassifier(criterion='entropy', max_depth=8, max_features=10),\n",
      "               DecisionTreeClassifier(criterion='entropy', max_depth=8, max_features=10),\n",
      "               DecisionTreeClassifier(criterion='entropy', max_depth=8, max_features=10),\n",
      "               DecisionTreeClassifier(criterion='entropy', max_depth=8, max_features=10),\n",
      "               DecisionTreeClassifier(criterion='entropy', max_depth=8, max_features=10),\n",
      "               DecisionTreeClassifier(criterion='entropy', max_depth=8, max_features=10),\n",
      "               DecisionTreeClassifier(criterion='entropy', max_depth=8, max_features=10),\n",
      "               DecisionTreeClassifier(criterion='entropy', max_depth=8, max_features=10)),\n",
      " 'fit_time': array([0.00498629, 0.00399041, 0.00597191, 0.00398898, 0.00398946,\n",
      "       0.00299168, 0.00398946, 0.00399208]),\n",
      " 'score_time': array([0.00199461, 0.00299358, 0.00299263, 0.00099707, 0.00099659,\n",
      "       0.00199437, 0.00199461, 0.00199199]),\n",
      " 'test_score': array([0.9020979 , 0.91549296, 0.95774648, 0.92253521, 0.94405594,\n",
      "       0.91549296, 0.93661972, 0.96478873]),\n",
      " 'train_score': array([1., 1., 1., 1., 1., 1., 1., 1.])}\n",
      "\n",
      "Accuracy (Training): 1.00 (+/- 0.00)\n",
      "Accuracy (Testing):  0.93 (+/- 0.04)\n",
      "[[339  19]\n",
      " [ 20 191]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.95      0.95       358\n",
      "           1       0.91      0.91      0.91       211\n",
      "\n",
      "    accuracy                           0.93       569\n",
      "   macro avg       0.93      0.93      0.93       569\n",
      "weighted avg       0.93      0.93      0.93       569\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#rank 1 after grid search \n",
    "dt = DecisionTreeClassifier(criterion='entropy', max_depth=8, max_features=10, min_samples_split=2, splitter='best', random_state=None)\n",
    "\n",
    "rkf = RepeatedStratifiedKFold(n_splits=4,  n_repeats=2)\n",
    "scores = cross_validate(dt, X, y, cv=rkf, return_train_score=True, return_estimator=True)\n",
    "y_pred = cross_val_predict(dt, X, y, cv=6)\n",
    "\n",
    "pprint.pprint(scores)\n",
    "print()\n",
    "print(\"Accuracy (Training): %0.2f (+/- %0.2f)\" % (scores['train_score'].mean(), scores['train_score'].std() * 2))\n",
    "print(\"Accuracy (Testing):  %0.2f (+/- %0.2f)\" % (scores['test_score'].mean(), scores['test_score'].std() * 2))\n",
    "print(confusion_matrix(y, y_pred))\n",
    "report = classification_report(y, y_pred)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'estimator': (DecisionTreeClassifier(max_features=8, min_samples_split=4, splitter='random'),\n",
      "               DecisionTreeClassifier(max_features=8, min_samples_split=4, splitter='random'),\n",
      "               DecisionTreeClassifier(max_features=8, min_samples_split=4, splitter='random'),\n",
      "               DecisionTreeClassifier(max_features=8, min_samples_split=4, splitter='random'),\n",
      "               DecisionTreeClassifier(max_features=8, min_samples_split=4, splitter='random'),\n",
      "               DecisionTreeClassifier(max_features=8, min_samples_split=4, splitter='random'),\n",
      "               DecisionTreeClassifier(max_features=8, min_samples_split=4, splitter='random'),\n",
      "               DecisionTreeClassifier(max_features=8, min_samples_split=4, splitter='random')),\n",
      " 'fit_time': array([0.00301981, 0.00199604, 0.00299263, 0.00399041, 0.00298262,\n",
      "       0.00099707, 0.00199413, 0.00299335]),\n",
      " 'score_time': array([0.00100899, 0.00199294, 0.00201058, 0.00099659, 0.00099754,\n",
      "       0.00199485, 0.00099778, 0.00199199]),\n",
      " 'test_score': array([0.93006993, 0.90140845, 0.94366197, 0.92957746, 0.8951049 ,\n",
      "       0.93661972, 0.92253521, 0.92253521]),\n",
      " 'train_score': array([0.98826291, 0.9765808 , 0.98360656, 0.98360656, 0.99061033,\n",
      "       0.99297424, 0.98594848, 0.9882904 ])}\n",
      "\n",
      "Accuracy (Training): 0.99 (+/- 0.01)\n",
      "Accuracy (Testing):  0.92 (+/- 0.03)\n",
      "[[342  16]\n",
      " [ 17 194]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.96      0.95       358\n",
      "           1       0.92      0.92      0.92       211\n",
      "\n",
      "    accuracy                           0.94       569\n",
      "   macro avg       0.94      0.94      0.94       569\n",
      "weighted avg       0.94      0.94      0.94       569\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#rank 2 \n",
    "dt1 = DecisionTreeClassifier(criterion='gini', max_depth=None, max_features=8, min_samples_split=4, splitter='random', random_state=None)\n",
    "\n",
    "rkf = RepeatedStratifiedKFold(n_splits=4,  n_repeats=2)\n",
    "scores = cross_validate(dt1, X, y, cv=rkf, return_train_score=True, return_estimator=True)\n",
    "y_pred = cross_val_predict(dt1, X, y, cv=6)\n",
    "\n",
    "pprint.pprint(scores)\n",
    "print()\n",
    "print(\"Accuracy (Training): %0.2f (+/- %0.2f)\" % (scores['train_score'].mean(), scores['train_score'].std() * 2))\n",
    "print(\"Accuracy (Testing):  %0.2f (+/- %0.2f)\" % (scores['test_score'].mean(), scores['test_score'].std() * 2))\n",
    "print(confusion_matrix(y, y_pred))\n",
    "report = classification_report(y, y_pred)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'estimator': (DecisionTreeClassifier(max_features=8, min_samples_split=4),\n",
      "               DecisionTreeClassifier(max_features=8, min_samples_split=4),\n",
      "               DecisionTreeClassifier(max_features=8, min_samples_split=4),\n",
      "               DecisionTreeClassifier(max_features=8, min_samples_split=4),\n",
      "               DecisionTreeClassifier(max_features=8, min_samples_split=4),\n",
      "               DecisionTreeClassifier(max_features=8, min_samples_split=4),\n",
      "               DecisionTreeClassifier(max_features=8, min_samples_split=4),\n",
      "               DecisionTreeClassifier(max_features=8, min_samples_split=4)),\n",
      " 'fit_time': array([0.00497389, 0.00397825, 0.00495815, 0.00299215, 0.00299811,\n",
      "       0.00396681, 0.00298691, 0.00299168]),\n",
      " 'score_time': array([0.0009973 , 0.00196648, 0.00199604, 0.0009973 , 0.00099635,\n",
      "       0.00200629, 0.00099802, 0.00195742]),\n",
      " 'test_score': array([0.93006993, 0.88732394, 0.92957746, 0.93661972, 0.95104895,\n",
      "       0.91549296, 0.93661972, 0.95774648]),\n",
      " 'train_score': array([0.99295775, 0.99531616, 0.99297424, 0.99531616, 0.99061033,\n",
      "       0.99765808, 0.99531616, 0.99765808])}\n",
      "\n",
      "Accuracy (Training): 0.99 (+/- 0.00)\n",
      "Accuracy (Testing):  0.93 (+/- 0.04)\n",
      "[[336  22]\n",
      " [ 23 188]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.94      0.94       358\n",
      "           1       0.90      0.89      0.89       211\n",
      "\n",
      "    accuracy                           0.92       569\n",
      "   macro avg       0.92      0.91      0.92       569\n",
      "weighted avg       0.92      0.92      0.92       569\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#rank 3\n",
    "dt2 = DecisionTreeClassifier(criterion='gini', max_depth=None, max_features=8, min_samples_split=4, splitter='best', random_state=None)\n",
    "\n",
    "rkf = RepeatedStratifiedKFold(n_splits=4,  n_repeats=2)\n",
    "scores = cross_validate(dt2, X, y, cv=rkf, return_train_score=True, return_estimator=True)\n",
    "y_pred = cross_val_predict(dt2, X, y, cv=6)\n",
    "\n",
    "pprint.pprint(scores)\n",
    "print()\n",
    "print(\"Accuracy (Training): %0.2f (+/- %0.2f)\" % (scores['train_score'].mean(), scores['train_score'].std() * 2))\n",
    "print(\"Accuracy (Testing):  %0.2f (+/- %0.2f)\" % (scores['test_score'].mean(), scores['test_score'].std() * 2))\n",
    "print(confusion_matrix(y, y_pred))\n",
    "report = classification_report(y, y_pred)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'estimator': (DecisionTreeClassifier(max_features=10),\n",
      "               DecisionTreeClassifier(max_features=10),\n",
      "               DecisionTreeClassifier(max_features=10),\n",
      "               DecisionTreeClassifier(max_features=10),\n",
      "               DecisionTreeClassifier(max_features=10),\n",
      "               DecisionTreeClassifier(max_features=10),\n",
      "               DecisionTreeClassifier(max_features=10),\n",
      "               DecisionTreeClassifier(max_features=10)),\n",
      " 'fit_time': array([0.00401831, 0.00500846, 0.00299335, 0.00402713, 0.00402617,\n",
      "       0.00303078, 0.00396442, 0.00300574]),\n",
      " 'score_time': array([0.0029645 , 0.00096011, 0.00196099, 0.00099635, 0.00096083,\n",
      "       0.00199294, 0.00102162, 0.00099778]),\n",
      " 'test_score': array([0.94405594, 0.93661972, 0.9084507 , 0.91549296, 0.94405594,\n",
      "       0.92957746, 0.92253521, 0.88028169]),\n",
      " 'train_score': array([1., 1., 1., 1., 1., 1., 1., 1.])}\n",
      "\n",
      "Accuracy (Training): 1.00 (+/- 0.00)\n",
      "Accuracy (Testing):  0.92 (+/- 0.04)\n",
      "[[336  22]\n",
      " [ 20 191]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.94      0.94       358\n",
      "           1       0.90      0.91      0.90       211\n",
      "\n",
      "    accuracy                           0.93       569\n",
      "   macro avg       0.92      0.92      0.92       569\n",
      "weighted avg       0.93      0.93      0.93       569\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#rank 4\n",
    "dt3 = DecisionTreeClassifier(criterion='gini', max_depth=None, max_features=10, min_samples_split=2, splitter='best', random_state=None)\n",
    "\n",
    "rkf = RepeatedStratifiedKFold(n_splits=4,  n_repeats=2)\n",
    "scores = cross_validate(dt3, X, y, cv=rkf, return_train_score=True, return_estimator=True)\n",
    "y_pred = cross_val_predict(dt3, X, y, cv=6)\n",
    "\n",
    "pprint.pprint(scores)\n",
    "print()\n",
    "print(\"Accuracy (Training): %0.2f (+/- %0.2f)\" % (scores['train_score'].mean(), scores['train_score'].std() * 2))\n",
    "print(\"Accuracy (Testing):  %0.2f (+/- %0.2f)\" % (scores['test_score'].mean(), scores['test_score'].std() * 2))\n",
    "print(confusion_matrix(y, y_pred))\n",
    "report = classification_report(y, y_pred)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'estimator': (RandomForestClassifier(max_depth=15, max_features=10),\n",
      "               RandomForestClassifier(max_depth=15, max_features=10),\n",
      "               RandomForestClassifier(max_depth=15, max_features=10),\n",
      "               RandomForestClassifier(max_depth=15, max_features=10),\n",
      "               RandomForestClassifier(max_depth=15, max_features=10),\n",
      "               RandomForestClassifier(max_depth=15, max_features=10),\n",
      "               RandomForestClassifier(max_depth=15, max_features=10),\n",
      "               RandomForestClassifier(max_depth=15, max_features=10)),\n",
      " 'fit_time': array([0.18252158, 0.18454432, 0.18351841, 0.18948269, 0.20844126,\n",
      "       0.2034936 , 0.21741986, 0.23341274]),\n",
      " 'score_time': array([0.00893641, 0.00798535, 0.00797296, 0.01193094, 0.00997257,\n",
      "       0.01392436, 0.00897551, 0.01395917]),\n",
      " 'test_score': array([0.97902098, 0.93661972, 0.94366197, 0.97183099, 0.97902098,\n",
      "       0.9084507 , 0.97183099, 0.95774648]),\n",
      " 'train_score': array([1., 1., 1., 1., 1., 1., 1., 1.])}\n",
      "\n",
      "Accuracy (Training): 1.00 (+/- 0.00)\n",
      "Accuracy (Testing):  0.96 (+/- 0.05)\n",
      "[[350   8]\n",
      " [ 11 200]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.98      0.97       358\n",
      "           1       0.96      0.95      0.95       211\n",
      "\n",
      "    accuracy                           0.97       569\n",
      "   macro avg       0.97      0.96      0.96       569\n",
      "weighted avg       0.97      0.97      0.97       569\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Model1\n",
    "#creterion specified as in the other one should be gini by default\n",
    "rft3 = RandomForestClassifier(criterion='gini', n_estimators=100, max_features=10, max_depth=15, random_state=None)\n",
    "\n",
    "rkf = RepeatedStratifiedKFold(n_splits=4,  n_repeats=2)\n",
    "scores = cross_validate(rft3, X, y, cv=rkf, return_train_score=True, return_estimator=True)\n",
    "y_pred = cross_val_predict(rft3, X, y, cv=6)\n",
    "\n",
    "pprint.pprint(scores)\n",
    "print()\n",
    "print(\"Accuracy (Training): %0.2f (+/- %0.2f)\" % (scores['train_score'].mean(), scores['train_score'].std() * 2))\n",
    "print(\"Accuracy (Testing):  %0.2f (+/- %0.2f)\" % (scores['test_score'].mean(), scores['test_score'].std() * 2))\n",
    "print(confusion_matrix(y, y_pred))\n",
    "report = classification_report(y, y_pred)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'estimator': (RandomForestClassifier(criterion='entropy', max_depth=15, max_features=10),\n",
      "               RandomForestClassifier(criterion='entropy', max_depth=15, max_features=10),\n",
      "               RandomForestClassifier(criterion='entropy', max_depth=15, max_features=10),\n",
      "               RandomForestClassifier(criterion='entropy', max_depth=15, max_features=10),\n",
      "               RandomForestClassifier(criterion='entropy', max_depth=15, max_features=10),\n",
      "               RandomForestClassifier(criterion='entropy', max_depth=15, max_features=10),\n",
      "               RandomForestClassifier(criterion='entropy', max_depth=15, max_features=10),\n",
      "               RandomForestClassifier(criterion='entropy', max_depth=15, max_features=10)),\n",
      " 'fit_time': array([0.21143436, 0.23237634, 0.24830198, 0.21043587, 0.2074523 ,\n",
      "       0.26333547, 0.22842932, 0.22743511]),\n",
      " 'score_time': array([0.0100069 , 0.01292944, 0.00897717, 0.00798225, 0.00898099,\n",
      "       0.01193118, 0.00898123, 0.00899029]),\n",
      " 'test_score': array([0.95804196, 0.97183099, 0.96478873, 0.95774648, 0.95104895,\n",
      "       0.98591549, 0.96478873, 0.96478873]),\n",
      " 'train_score': array([1.        , 1.        , 1.        , 0.99765808, 1.        ,\n",
      "       1.        , 1.        , 1.        ])}\n",
      "\n",
      "Accuracy (Training): 1.00 (+/- 0.00)\n",
      "Accuracy (Testing):  0.96 (+/- 0.02)\n",
      "[[351   7]\n",
      " [ 13 198]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.98      0.97       358\n",
      "           1       0.97      0.94      0.95       211\n",
      "\n",
      "    accuracy                           0.96       569\n",
      "   macro avg       0.97      0.96      0.96       569\n",
      "weighted avg       0.96      0.96      0.96       569\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Model 2\n",
    "#creterion specified as in the other one should be gini by default\n",
    "rft3 = RandomForestClassifier(criterion='entropy', n_estimators=100, max_features=10, max_depth=15, random_state=None)\n",
    "\n",
    "rkf = RepeatedStratifiedKFold(n_splits=4,  n_repeats=2)\n",
    "scores = cross_validate(rft3, X, y, cv=rkf, return_train_score=True, return_estimator=True)\n",
    "y_pred = cross_val_predict(rft3, X, y, cv=6)\n",
    "\n",
    "pprint.pprint(scores)\n",
    "print()\n",
    "print(\"Accuracy (Training): %0.2f (+/- %0.2f)\" % (scores['train_score'].mean(), scores['train_score'].std() * 2))\n",
    "print(\"Accuracy (Testing):  %0.2f (+/- %0.2f)\" % (scores['test_score'].mean(), scores['test_score'].std() * 2))\n",
    "print(confusion_matrix(y, y_pred))\n",
    "report = classification_report(y, y_pred)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Decision tree vs Random Fortes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-ad1660e2ee20>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdt_acc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mrf_acc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mruns\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mruns\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "dt_acc = np.array([])\n",
    "rf_acc = np.array([])\n",
    "runs = 100\n",
    "\n",
    "for x in range(runs):\n",
    "    \n",
    "    # splitting the dataset each run, just to get more variation in the results for this example\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=None, stratify=df['Diagnosis'])\n",
    "    \n",
    "    # DT model 1\n",
    "    dt = DecisionTreeClassifier(criterion='entropy', max_depth=8, max_features=10, min_samples_split=2, splitter='best', random_state=None)\n",
    "    dt = dt.fit(X_train,y_train)\n",
    "    y_pred = dt.predict(X_test)\n",
    "    dt_accuracy = np.append(dt_acc, metrics.accuracy_score(y_test, y_pred))\n",
    "    \n",
    "    # Random Forest with 10 trees (model 2)\n",
    "    rf = RandomForestClassifier(criterion='entropy', n_estimators=100, max_features=10, max_depth=15, random_state=None)\n",
    "    rf = rf.fit(X_train,y_train)\n",
    "    y_pred = rf.predict(X_test)\n",
    "    rf_accuracy = np.append(rf_acc, metrics.accuracy_score(y_test, y_pred))\n",
    "\n",
    "print(\"Done...\")\n",
    "print(\" - DT accuracy: %0.2f (+/- %0.2f)\" % (dt_accuracy.mean(), dt_accuracy.std() * 2))\n",
    "print(\" - RF accuracy: %0.2f (+/- %0.2f)\" % (rf_accuracy.mean(), rf_accuracy.std() * 2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'estimator': (GaussianNB(),\n",
      "               GaussianNB(),\n",
      "               GaussianNB(),\n",
      "               GaussianNB(),\n",
      "               GaussianNB(),\n",
      "               GaussianNB(),\n",
      "               GaussianNB(),\n",
      "               GaussianNB(),\n",
      "               GaussianNB(),\n",
      "               GaussianNB(),\n",
      "               GaussianNB(),\n",
      "               GaussianNB(),\n",
      "               GaussianNB(),\n",
      "               GaussianNB(),\n",
      "               GaussianNB(),\n",
      "               GaussianNB(),\n",
      "               GaussianNB(),\n",
      "               GaussianNB(),\n",
      "               GaussianNB(),\n",
      "               GaussianNB()),\n",
      " 'fit_time': array([0.00498891, 0.002985  , 0.00498319, 0.00299573, 0.00398827,\n",
      "       0.00299191, 0.00299072, 0.00199437, 0.00199461, 0.00199413,\n",
      "       0.00299168, 0.00199413, 0.00199509, 0.00199604, 0.00299001,\n",
      "       0.00198364, 0.00299144, 0.00302196, 0.00199246, 0.00302529]),\n",
      " 'score_time': array([0.00303268, 0.00199604, 0.00199509, 0.00298882, 0.00199604,\n",
      "       0.00199604, 0.00199533, 0.00199533, 0.00199461, 0.00199485,\n",
      "       0.00099802, 0.00199461, 0.00099659, 0.00199342, 0.00202894,\n",
      "       0.00200725, 0.00196362, 0.00099754, 0.00199437, 0.00199103]),\n",
      " 'test_score': array([0.92307692, 0.95070423, 0.92957746, 0.91549296, 0.93006993,\n",
      "       0.95070423, 0.92957746, 0.91549296, 0.95804196, 0.92957746,\n",
      "       0.8943662 , 0.94366197, 0.93006993, 0.96478873, 0.9084507 ,\n",
      "       0.94366197, 0.93706294, 0.95774648, 0.92253521, 0.92253521]),\n",
      " 'train_score': array([0.93661972, 0.92974239, 0.95081967, 0.93208431, 0.95070423,\n",
      "       0.93442623, 0.92740047, 0.94145199, 0.93661972, 0.92271663,\n",
      "       0.94145199, 0.93676815, 0.92488263, 0.92974239, 0.94847775,\n",
      "       0.93442623, 0.94131455, 0.92505855, 0.94145199, 0.93676815])}\n",
      "\n",
      "Accuracy (Training): 0.94 (+/- 0.02)\n",
      "Accuracy (Testing):  0.93 (+/- 0.04)\n",
      "[[341  17]\n",
      " [ 24 187]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.95      0.94       358\n",
      "           1       0.92      0.89      0.90       211\n",
      "\n",
      "    accuracy                           0.93       569\n",
      "   macro avg       0.93      0.92      0.92       569\n",
      "weighted avg       0.93      0.93      0.93       569\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#model1\n",
    "gaussianNB = GaussianNB()\n",
    "\n",
    "rkf = RepeatedStratifiedKFold(n_splits=4,  n_repeats=5)\n",
    "scores = cross_validate(gaussianNB, X, y, cv=rkf, return_train_score=True, return_estimator=True)\n",
    "y_pred = cross_val_predict(gaussianNB, X, y, cv=6)\n",
    "\n",
    "pprint.pprint(scores)\n",
    "print()\n",
    "print(\"Accuracy (Training): %0.2f (+/- %0.2f)\" % (scores['train_score'].mean(), scores['train_score'].std() * 2))\n",
    "print(\"Accuracy (Testing):  %0.2f (+/- %0.2f)\" % (scores['test_score'].mean(), scores['test_score'].std() * 2))\n",
    "print(confusion_matrix(y, y_pred))\n",
    "report = classification_report(y, y_pred)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'estimator': (MultinomialNB(),\n",
      "               MultinomialNB(),\n",
      "               MultinomialNB(),\n",
      "               MultinomialNB(),\n",
      "               MultinomialNB(),\n",
      "               MultinomialNB(),\n",
      "               MultinomialNB(),\n",
      "               MultinomialNB(),\n",
      "               MultinomialNB(),\n",
      "               MultinomialNB(),\n",
      "               MultinomialNB(),\n",
      "               MultinomialNB(),\n",
      "               MultinomialNB(),\n",
      "               MultinomialNB(),\n",
      "               MultinomialNB(),\n",
      "               MultinomialNB(),\n",
      "               MultinomialNB(),\n",
      "               MultinomialNB(),\n",
      "               MultinomialNB(),\n",
      "               MultinomialNB()),\n",
      " 'fit_time': array([0.0099721 , 0.00202179, 0.00398803, 0.00299048, 0.00199437,\n",
      "       0.00398922, 0.00199413, 0.00296497, 0.00199795, 0.00199556,\n",
      "       0.00299883, 0.00199461, 0.00199294, 0.00196075, 0.00199819,\n",
      "       0.00204587, 0.00199699, 0.00195408, 0.00199485, 0.00299048]),\n",
      " 'score_time': array([0.00199461, 0.00100327, 0.00200248, 0.0009973 , 0.00199461,\n",
      "       0.00199533, 0.00199485, 0.0020256 , 0.00099611, 0.00199389,\n",
      "       0.00198793, 0.00097036, 0.00099778, 0.0020268 , 0.00195193,\n",
      "       0.00198531, 0.0009954 , 0.00199509, 0.00099754, 0.00099683]),\n",
      " 'test_score': array([0.77622378, 0.84507042, 0.83098592, 0.88028169, 0.81818182,\n",
      "       0.82394366, 0.86619718, 0.80985915, 0.81118881, 0.83098592,\n",
      "       0.81690141, 0.85915493, 0.8041958 , 0.85915493, 0.85915493,\n",
      "       0.82394366, 0.88811189, 0.81690141, 0.80985915, 0.83098592]),\n",
      " 'train_score': array([0.85680751, 0.82903981, 0.83138173, 0.82201405, 0.83802817,\n",
      "       0.83606557, 0.83138173, 0.84074941, 0.85446009, 0.81733021,\n",
      "       0.83372365, 0.83606557, 0.84741784, 0.82435597, 0.82201405,\n",
      "       0.84777518, 0.8286385 , 0.83840749, 0.83372365, 0.83138173])}\n",
      "\n",
      "Accuracy (Training): 0.84 (+/- 0.02)\n",
      "Accuracy (Testing):  0.83 (+/- 0.05)\n",
      "[[357   1]\n",
      " [ 93 118]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      1.00      0.88       358\n",
      "           1       0.99      0.56      0.72       211\n",
      "\n",
      "    accuracy                           0.83       569\n",
      "   macro avg       0.89      0.78      0.80       569\n",
      "weighted avg       0.87      0.83      0.82       569\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Model 2\n",
    "multinomialNB = MultinomialNB()\n",
    "\n",
    "rkf = RepeatedStratifiedKFold(n_splits=4,  n_repeats=5)\n",
    "scores = cross_validate(multinomialNB, X, y, cv=rkf, return_train_score=True, return_estimator=True)\n",
    "y_pred = cross_val_predict(multinomialNB, X, y, cv=6)\n",
    "\n",
    "pprint.pprint(scores)\n",
    "print()\n",
    "print(\"Accuracy (Training): %0.2f (+/- %0.2f)\" % (scores['train_score'].mean(), scores['train_score'].std() * 2))\n",
    "print(\"Accuracy (Testing):  %0.2f (+/- %0.2f)\" % (scores['test_score'].mean(), scores['test_score'].std() * 2))\n",
    "print(confusion_matrix(y, y_pred))\n",
    "report = classification_report(y, y_pred)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'estimator': (BernoulliNB(),\n",
      "               BernoulliNB(),\n",
      "               BernoulliNB(),\n",
      "               BernoulliNB(),\n",
      "               BernoulliNB(),\n",
      "               BernoulliNB(),\n",
      "               BernoulliNB(),\n",
      "               BernoulliNB(),\n",
      "               BernoulliNB(),\n",
      "               BernoulliNB(),\n",
      "               BernoulliNB(),\n",
      "               BernoulliNB(),\n",
      "               BernoulliNB(),\n",
      "               BernoulliNB(),\n",
      "               BernoulliNB(),\n",
      "               BernoulliNB(),\n",
      "               BernoulliNB(),\n",
      "               BernoulliNB(),\n",
      "               BernoulliNB(),\n",
      "               BernoulliNB()),\n",
      " 'fit_time': array([0.00498629, 0.00299239, 0.00299215, 0.00399041, 0.00302649,\n",
      "       0.00299239, 0.0020113 , 0.00199389, 0.00296617, 0.00196624,\n",
      "       0.00299191, 0.00402331, 0.00203061, 0.00298834, 0.00399876,\n",
      "       0.00497818, 0.00199413, 0.00299239, 0.00299001, 0.0039525 ]),\n",
      " 'score_time': array([0.00398922, 0.00099826, 0.00099754, 0.00199676, 0.00099206,\n",
      "       0.00196528, 0.0019865 , 0.00199509, 0.00199389, 0.00202441,\n",
      "       0.00096965, 0.00199771, 0.00199699, 0.00295758, 0.00199437,\n",
      "       0.00296879, 0.00200582, 0.00295377, 0.00303006, 0.0029912 ]),\n",
      " 'test_score': array([0.62937063, 0.63380282, 0.59859155, 0.61971831, 0.62237762,\n",
      "       0.61971831, 0.6056338 , 0.63380282, 0.62237762, 0.61267606,\n",
      "       0.61267606, 0.63380282, 0.62237762, 0.6056338 , 0.62676056,\n",
      "       0.62676056, 0.62237762, 0.61971831, 0.61971831, 0.61971831]),\n",
      " 'train_score': array([0.6314554 , 0.6323185 , 0.63466042, 0.6323185 , 0.63380282,\n",
      "       0.6323185 , 0.63466042, 0.62997658, 0.6314554 , 0.63466042,\n",
      "       0.6323185 , 0.6323185 , 0.63380282, 0.63466042, 0.6323185 ,\n",
      "       0.62997658, 0.6314554 , 0.6323185 , 0.63466042, 0.6323185 ])}\n",
      "\n",
      "Accuracy (Training): 0.63 (+/- 0.00)\n",
      "Accuracy (Testing):  0.62 (+/- 0.02)\n",
      "[[351   7]\n",
      " [209   2]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.98      0.76       358\n",
      "           1       0.22      0.01      0.02       211\n",
      "\n",
      "    accuracy                           0.62       569\n",
      "   macro avg       0.42      0.49      0.39       569\n",
      "weighted avg       0.48      0.62      0.49       569\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Model 3\n",
    "bernoulliNB = BernoulliNB()\n",
    "rkf = RepeatedStratifiedKFold(n_splits=4,  n_repeats=5)\n",
    "scores = cross_validate(bernoulliNB, X, y, cv=rkf, return_train_score=True, return_estimator=True)\n",
    "y_pred = cross_val_predict(bernoulliNB, X, y, cv=6)\n",
    "\n",
    "pprint.pprint(scores)\n",
    "print()\n",
    "print(\"Accuracy (Training): %0.2f (+/- %0.2f)\" % (scores['train_score'].mean(), scores['train_score'].std() * 2))\n",
    "print(\"Accuracy (Testing):  %0.2f (+/- %0.2f)\" % (scores['test_score'].mean(), scores['test_score'].std() * 2))\n",
    "print(confusion_matrix(y, y_pred))\n",
    "report = classification_report(y, y_pred)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#All three NB compared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Gaussian accuracy:    0.93 (+/- 0.04)\n",
      " Multinomial accuracy: 0.84 (+/- 0.05)\n",
      " Bernoulli accuracy:   0.62 (+/- 0.02)\n"
     ]
    }
   ],
   "source": [
    "gaussian = np.array([])\n",
    "muiltinomial = np.array([])\n",
    "bernoulli = np.array([])\n",
    "\n",
    "runs = 100\n",
    "for x in range(runs):\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=None, stratify=df['Diagnosis'])\n",
    "    \n",
    "    # Gaussian NB\n",
    "    gaussianNB = GaussianNB()\n",
    "    gaussianNB = gaussianNB.fit(X_train,y_train)\n",
    "    y_pred = gaussianNB.predict(X_test)\n",
    "    gaussian = np.append(gaussian, metrics.accuracy_score(y_test, y_pred))\n",
    "    \n",
    "    # Multinomial NB\n",
    "    multinomialNB = MultinomialNB()\n",
    "    multinomialNB = multinomialNB.fit(X_train,y_train)\n",
    "    y_pred = multinomialNB.predict(X_test)\n",
    "    muiltinomial = np.append(muiltinomial, metrics.accuracy_score(y_test, y_pred))\n",
    "    \n",
    "    # Bernoulli NB\n",
    "    bernoulliNB = BernoulliNB()\n",
    "    bernoulliNB = bernoulliNB.fit(X_train,y_train)\n",
    "    y_pred = bernoulliNB.predict(X_test)\n",
    "    bernoulli = np.append(bernoulli, metrics.accuracy_score(y_test, y_pred))\n",
    "\n",
    "\n",
    "print(\" Gaussian accuracy:    %0.2f (+/- %0.2f)\" % (gaussian.mean(), gaussian.std() * 2))\n",
    "print(\" Multinomial accuracy: %0.2f (+/- %0.2f)\" % (muiltinomial.mean(), muiltinomial.std() * 2))\n",
    "print(\" Bernoulli accuracy:   %0.2f (+/- %0.2f)\" % (bernoulli.mean(), bernoulli.std() * 2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
