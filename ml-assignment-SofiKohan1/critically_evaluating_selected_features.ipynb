{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data, Datasets & Utils\n",
    "import pandas as pd\n",
    "from pandas.plotting import scatter_matrix\n",
    "import pprint\n",
    "import numpy as np\n",
    "from time import time\n",
    "from numpy import log2 as log\n",
    "\n",
    "# Validation methods\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Metrics\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Classifiers\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "\n",
    "\n",
    "# Hyper-parameter optimisation\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# Feature selection & feature engineering\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Stats\n",
    "from scipy.stats import randint as sp_randint\n",
    "from scipy.stats import pearsonr\n",
    "from scipy.stats import spearmanr\n",
    "from scipy.stats import shapiro     # Shapiro Wilk\n",
    "from scipy.stats import normaltest  # D’Agostino’s K^2\n",
    "from scipy.stats import anderson    # Anderson-Darling\n",
    "from scipy.stats import ttest_ind    # independent student t-test; assumes normality\n",
    "from scipy.stats import mannwhitneyu # non-parametric; doesn't assume normality\n",
    "\n",
    "# Visualisation\n",
    "import matplotlib.pyplot as plot \n",
    "import seaborn as sns\n",
    "from IPython.display import SVG\n",
    "from graphviz import Source\n",
    "from IPython.display import display\n",
    "from sklearn.tree import export_graphviz\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape:\n",
      " (569, 32)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 569 entries, 0 to 568\n",
      "Data columns (total 32 columns):\n",
      " #   Column                      Non-Null Count  Dtype  \n",
      "---  ------                      --------------  -----  \n",
      " 0   ID                          568 non-null    float64\n",
      " 1   Radius (Mean)               550 non-null    float64\n",
      " 2   Texture (Mean)              568 non-null    float64\n",
      " 3   Perimeter (Mean)            567 non-null    float64\n",
      " 4   Area (Mean)                 566 non-null    float64\n",
      " 5   Smoothness (Mean)           567 non-null    float64\n",
      " 6   Compactness (Mean)          566 non-null    float64\n",
      " 7   Concavity (Mean)            569 non-null    float64\n",
      " 8   Concave Points (Mean)       569 non-null    float64\n",
      " 9   Symmetry (Mean)             566 non-null    float64\n",
      " 10  Fractal Dimension (Mean)    567 non-null    float64\n",
      " 11  Radius (Error)              551 non-null    float64\n",
      " 12   Texture (Error)            567 non-null    float64\n",
      " 13   Perimeter (Error)          568 non-null    float64\n",
      " 14   Area (Error)               567 non-null    float64\n",
      " 15   Smoothness (Error)         566 non-null    float64\n",
      " 16   Compactness (Error)        568 non-null    float64\n",
      " 17   Concavity (Error)          568 non-null    float64\n",
      " 18   Concave Points (Error)     567 non-null    float64\n",
      " 19   Symmetry (Error)           568 non-null    float64\n",
      " 20   Fractal Dimension (Error)  567 non-null    float64\n",
      " 21   Radius (Worst)             551 non-null    float64\n",
      " 22   Texture (Worst)            566 non-null    float64\n",
      " 23   Perimeter (Worst)          567 non-null    float64\n",
      " 24   Area (Worst)               566 non-null    float64\n",
      " 25   Smoothness (Worst)         569 non-null    float64\n",
      " 26   Compactness (Worst)        565 non-null    float64\n",
      " 27   Concavity (Worst)          567 non-null    float64\n",
      " 28  Concave Points (Worst)      566 non-null    float64\n",
      " 29  Symmetry (Worst)            566 non-null    float64\n",
      " 30  Fractal Dimension (Worst)   565 non-null    float64\n",
      " 31  Diagnosis                   569 non-null    object \n",
      "dtypes: float64(31), object(1)\n",
      "memory usage: 142.4+ KB\n",
      "None\n",
      "\n",
      "Unique Values in 'Diagnosis' ['M', 'B']\n"
     ]
    }
   ],
   "source": [
    "#Reading data set file\n",
    "\n",
    "df = pd.read_csv('data/breast-cancer.csv')\n",
    "print(\"Shape:\\n\",df.shape) #tells us how many rows and columns the data structer has got\n",
    "print(df.info())\n",
    "df.head()\n",
    "print(\"\\nUnique Values in 'Diagnosis'\", list(df.Diagnosis.unique()))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Texture (Mean)', 'Area (Mean)', 'Compactness (Mean)',\n",
      "       'Concavity (Mean)', ' Perimeter (Worst)', ' Area (Worst)',\n",
      "       ' Smoothness (Worst)', 'Concave Points (Worst)', 'Diagnosis'],\n",
      "      dtype='object')\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 569 entries, 0 to 568\n",
      "Data columns (total 9 columns):\n",
      " #   Column                  Non-Null Count  Dtype  \n",
      "---  ------                  --------------  -----  \n",
      " 0   Texture (Mean)          568 non-null    float64\n",
      " 1   Area (Mean)             566 non-null    float64\n",
      " 2   Compactness (Mean)      566 non-null    float64\n",
      " 3   Concavity (Mean)        569 non-null    float64\n",
      " 4    Perimeter (Worst)      567 non-null    float64\n",
      " 5    Area (Worst)           566 non-null    float64\n",
      " 6    Smoothness (Worst)     569 non-null    float64\n",
      " 7   Concave Points (Worst)  566 non-null    float64\n",
      " 8   Diagnosis               569 non-null    object \n",
      "dtypes: float64(8), object(1)\n",
      "memory usage: 40.1+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "df = df.drop(columns = ['ID', 'Radius (Mean)', 'Perimeter (Mean)',\n",
    "        'Smoothness (Mean)', \n",
    "        'Concave Points (Mean)', 'Symmetry (Mean)',\n",
    "       'Fractal Dimension (Mean)', 'Radius (Error)', ' Texture (Error)',\n",
    "       ' Perimeter (Error)', ' Area (Error)', ' Smoothness (Error)',\n",
    "       ' Concavity (Error)', ' Concave Points (Error)', ' Compactness (Error)',\n",
    "       ' Symmetry (Error)', ' Fractal Dimension (Error)', ' Radius (Worst)',\n",
    "       ' Texture (Worst)', ' Compactness (Worst)', ' Concavity (Worst)',\n",
    "       'Symmetry (Worst)', 'Fractal Dimension (Worst)'])\n",
    "\n",
    "print(df.columns)\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "df = df.fillna(df.mean())\n",
    "df.isnull().sum()\n",
    "\n",
    "df['Diagnosis'].replace('M', 1,inplace=True)\n",
    "df['Diagnosis'].replace('B', 0,inplace=True)\n",
    "\n",
    "names = df.columns\n",
    "scaler = MinMaxScaler() \n",
    "df = scaler.fit_transform(df) \n",
    "df = pd.DataFrame(df, columns=names)\n",
    "\n",
    "# Splits the Pandas DataFrame into a feature matrix (X) and class/label vector (y)\n",
    "X = df.iloc[:,:5]\n",
    "y = df['Diagnosis']\n",
    "\n",
    "# Transform class labels to numeric labels\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(y)\n",
    "y = le.transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Nearest Neighbors \n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'estimator': (KNeighborsClassifier(p=3),\n",
      "               KNeighborsClassifier(p=3),\n",
      "               KNeighborsClassifier(p=3),\n",
      "               KNeighborsClassifier(p=3),\n",
      "               KNeighborsClassifier(p=3),\n",
      "               KNeighborsClassifier(p=3),\n",
      "               KNeighborsClassifier(p=3),\n",
      "               KNeighborsClassifier(p=3),\n",
      "               KNeighborsClassifier(p=3),\n",
      "               KNeighborsClassifier(p=3),\n",
      "               KNeighborsClassifier(p=3),\n",
      "               KNeighborsClassifier(p=3)),\n",
      " 'fit_time': array([0.0029912 , 0.00299096, 0.00199509, 0.00299191, 0.00299191,\n",
      "       0.00299191, 0.00299144, 0.00299239, 0.00199437, 0.00199509,\n",
      "       0.00199437, 0.00299239]),\n",
      " 'score_time': array([0.00997686, 0.00897527, 0.00997424, 0.00897527, 0.00698137,\n",
      "       0.0089736 , 0.00797892, 0.00897527, 0.00797796, 0.0079782 ,\n",
      "       0.0079782 , 0.00698137]),\n",
      " 'test_score': array([0.89473684, 0.92631579, 0.95789474, 0.93684211, 0.94736842,\n",
      "       0.94680851, 0.88421053, 0.96842105, 0.93684211, 0.93684211,\n",
      "       0.92631579, 0.90425532]),\n",
      " 'train_score': array([0.9556962 , 0.94725738, 0.9535865 , 0.9535865 , 0.94303797,\n",
      "       0.94526316, 0.9535865 , 0.93881857, 0.94936709, 0.94514768,\n",
      "       0.95147679, 0.95368421])}\n",
      "\n",
      "Accuracy (Training): 0.95 (+/- 0.01)\n",
      "Accuracy (Testing):  0.93 (+/- 0.05)\n",
      "[[339  19]\n",
      " [ 20 191]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.95      0.95       358\n",
      "           1       0.91      0.91      0.91       211\n",
      "\n",
      "    accuracy                           0.93       569\n",
      "   macro avg       0.93      0.93      0.93       569\n",
      "weighted avg       0.93      0.93      0.93       569\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold #this seems pretty good one\n",
    "\n",
    "# Creating the model, training and testing it\n",
    "k = 5\n",
    "model = KNeighborsClassifier(n_neighbors=k, p=3, metric='minkowski')\n",
    "\n",
    "#random_state = 12883823 36851234\n",
    "rkf = RepeatedStratifiedKFold(n_splits=6, n_repeats=2,\n",
    "      random_state=4)\n",
    "scores = cross_validate(model, X, y, cv=rkf, return_train_score=True, return_estimator=True)\n",
    "\n",
    "y_pred = cross_val_predict(model, X, y, cv=6)\n",
    "\n",
    "# Printing results\n",
    "pprint.pprint(scores)\n",
    "print()\n",
    "\n",
    "print(\"Accuracy (Training): %0.2f (+/- %0.2f)\" % (scores['train_score'].mean(), scores['train_score'].std() * 2))\n",
    "print(\"Accuracy (Testing):  %0.2f (+/- %0.2f)\" % (scores['test_score'].mean(), scores['test_score'].std() * 2))\n",
    "print(confusion_matrix(y, y_pred)) \n",
    "report = classification_report(y, y_pred)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'estimator': (KNeighborsClassifier(metric='manhattan', weights='distance'),\n",
      "               KNeighborsClassifier(metric='manhattan', weights='distance'),\n",
      "               KNeighborsClassifier(metric='manhattan', weights='distance'),\n",
      "               KNeighborsClassifier(metric='manhattan', weights='distance'),\n",
      "               KNeighborsClassifier(metric='manhattan', weights='distance'),\n",
      "               KNeighborsClassifier(metric='manhattan', weights='distance'),\n",
      "               KNeighborsClassifier(metric='manhattan', weights='distance'),\n",
      "               KNeighborsClassifier(metric='manhattan', weights='distance')),\n",
      " 'fit_time': array([0.00398898, 0.00399065, 0.00199747, 0.00399613, 0.00299168,\n",
      "       0.00299239, 0.00199413, 0.00199604]),\n",
      " 'score_time': array([0.00299239, 0.00299191, 0.00398827, 0.00298572, 0.0039885 ,\n",
      "       0.00199461, 0.00199485, 0.00199294]),\n",
      " 'test_score': array([0.93706294, 0.92253521, 0.92957746, 0.93661972, 0.94405594,\n",
      "       0.91549296, 0.93661972, 0.95774648]),\n",
      " 'train_score': array([1., 1., 1., 1., 1., 1., 1., 1.])}\n",
      "\n",
      "Accuracy (Training): 1.00 (+/- 0.00)\n",
      "Accuracy (Testing):  0.93 (+/- 0.02)\n",
      "[[346  12]\n",
      " [ 20 191]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.97      0.96       358\n",
      "           1       0.94      0.91      0.92       211\n",
      "\n",
      "    accuracy                           0.94       569\n",
      "   macro avg       0.94      0.94      0.94       569\n",
      "weighted avg       0.94      0.94      0.94       569\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Creating the model, training and testing it\n",
    "k = 5\n",
    "model1 = KNeighborsClassifier(n_neighbors=k, weights='distance', metric='manhattan')\n",
    "\n",
    "#random_state = 12883823 36851234 random_state=12883823\n",
    "rkf = RepeatedStratifiedKFold(n_splits=4, n_repeats=2)\n",
    "scores = cross_validate(model1, X, y, cv=rkf, return_train_score=True, return_estimator=True)\n",
    "\n",
    "y_pred = cross_val_predict(model1, X, y, cv=6)\n",
    "\n",
    "# Printing results\n",
    "pprint.pprint(scores)\n",
    "print()\n",
    "#print(X_test)\n",
    "print(\"Accuracy (Training): %0.2f (+/- %0.2f)\" % (scores['train_score'].mean(), scores['train_score'].std() * 2))\n",
    "print(\"Accuracy (Testing):  %0.2f (+/- %0.2f)\" % (scores['test_score'].mean(), scores['test_score'].std() * 2))\n",
    "print(confusion_matrix(y, y_pred))\n",
    "report = classification_report(y, y_pred)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Decision Trees "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'estimator': (DecisionTreeClassifier(criterion='entropy', max_depth=8),\n",
      "               DecisionTreeClassifier(criterion='entropy', max_depth=8),\n",
      "               DecisionTreeClassifier(criterion='entropy', max_depth=8),\n",
      "               DecisionTreeClassifier(criterion='entropy', max_depth=8),\n",
      "               DecisionTreeClassifier(criterion='entropy', max_depth=8),\n",
      "               DecisionTreeClassifier(criterion='entropy', max_depth=8),\n",
      "               DecisionTreeClassifier(criterion='entropy', max_depth=8),\n",
      "               DecisionTreeClassifier(criterion='entropy', max_depth=8)),\n",
      " 'fit_time': array([0.00398993, 0.00702882, 0.00703764, 0.00593972, 0.0074389 ,\n",
      "       0.00606322, 0.00404477, 0.00501752]),\n",
      " 'score_time': array([0.00299096, 0.00299764, 0.0030756 , 0.00199533, 0.00249171,\n",
      "       0.00199676, 0.00199461, 0.00302958]),\n",
      " 'test_score': array([0.91608392, 0.95774648, 0.88028169, 0.93661972, 0.8951049 ,\n",
      "       0.87323944, 0.91549296, 0.94366197]),\n",
      " 'train_score': array([1.        , 0.99765808, 1.        , 1.        , 0.99530516,\n",
      "       0.99765808, 1.        , 0.99765808])}\n",
      "\n",
      "Accuracy (Training): 1.00 (+/- 0.00)\n",
      "Accuracy (Testing):  0.91 (+/- 0.06)\n",
      "[[335  23]\n",
      " [ 23 188]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.94      0.94       358\n",
      "           1       0.89      0.89      0.89       211\n",
      "\n",
      "    accuracy                           0.92       569\n",
      "   macro avg       0.91      0.91      0.91       569\n",
      "weighted avg       0.92      0.92      0.92       569\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#rank 1 after grid search \n",
    "dt = DecisionTreeClassifier(criterion='entropy', max_depth=8, min_samples_split=2, splitter='best', random_state=None)\n",
    "\n",
    "rkf = RepeatedStratifiedKFold(n_splits=4,  n_repeats=2)\n",
    "scores = cross_validate(dt, X, y, cv=rkf, return_train_score=True, return_estimator=True)\n",
    "y_pred = cross_val_predict(dt, X, y, cv=6)\n",
    "\n",
    "pprint.pprint(scores)\n",
    "print()\n",
    "print(\"Accuracy (Training): %0.2f (+/- %0.2f)\" % (scores['train_score'].mean(), scores['train_score'].std() * 2))\n",
    "print(\"Accuracy (Testing):  %0.2f (+/- %0.2f)\" % (scores['test_score'].mean(), scores['test_score'].std() * 2))\n",
    "print(confusion_matrix(y, y_pred))\n",
    "report = classification_report(y, y_pred)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'estimator': (DecisionTreeClassifier(min_samples_split=4, splitter='random'),\n",
      "               DecisionTreeClassifier(min_samples_split=4, splitter='random'),\n",
      "               DecisionTreeClassifier(min_samples_split=4, splitter='random'),\n",
      "               DecisionTreeClassifier(min_samples_split=4, splitter='random'),\n",
      "               DecisionTreeClassifier(min_samples_split=4, splitter='random'),\n",
      "               DecisionTreeClassifier(min_samples_split=4, splitter='random'),\n",
      "               DecisionTreeClassifier(min_samples_split=4, splitter='random'),\n",
      "               DecisionTreeClassifier(min_samples_split=4, splitter='random')),\n",
      " 'fit_time': array([0.00425196, 0.00403595, 0.00312734, 0.00502205, 0.00497556,\n",
      "       0.00366545, 0.00297284, 0.00199747]),\n",
      " 'score_time': array([0.00173497, 0.00194764, 0.00185919, 0.00316334, 0.00308943,\n",
      "       0.00202298, 0.00199389, 0.00299239]),\n",
      " 'test_score': array([0.94405594, 0.88732394, 0.93661972, 0.95070423, 0.94405594,\n",
      "       0.90140845, 0.90140845, 0.88732394]),\n",
      " 'train_score': array([0.97887324, 0.98126464, 0.97189696, 0.98126464, 0.98356808,\n",
      "       0.97892272, 0.97892272, 0.9882904 ])}\n",
      "\n",
      "Accuracy (Training): 0.98 (+/- 0.01)\n",
      "Accuracy (Testing):  0.92 (+/- 0.05)\n",
      "[[338  20]\n",
      " [ 20 191]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.94      0.94       358\n",
      "           1       0.91      0.91      0.91       211\n",
      "\n",
      "    accuracy                           0.93       569\n",
      "   macro avg       0.92      0.92      0.92       569\n",
      "weighted avg       0.93      0.93      0.93       569\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#rank 2 \n",
    "dt1 = DecisionTreeClassifier(criterion='gini', max_depth=None, min_samples_split=4, splitter='random', random_state=None)\n",
    "\n",
    "rkf = RepeatedStratifiedKFold(n_splits=4,  n_repeats=2)\n",
    "scores = cross_validate(dt1, X, y, cv=rkf, return_train_score=True, return_estimator=True)\n",
    "y_pred = cross_val_predict(dt1, X, y, cv=6)\n",
    "\n",
    "pprint.pprint(scores)\n",
    "print()\n",
    "print(\"Accuracy (Training): %0.2f (+/- %0.2f)\" % (scores['train_score'].mean(), scores['train_score'].std() * 2))\n",
    "print(\"Accuracy (Testing):  %0.2f (+/- %0.2f)\" % (scores['test_score'].mean(), scores['test_score'].std() * 2))\n",
    "print(confusion_matrix(y, y_pred))\n",
    "report = classification_report(y, y_pred)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'estimator': (DecisionTreeClassifier(min_samples_split=4),\n",
      "               DecisionTreeClassifier(min_samples_split=4),\n",
      "               DecisionTreeClassifier(min_samples_split=4),\n",
      "               DecisionTreeClassifier(min_samples_split=4),\n",
      "               DecisionTreeClassifier(min_samples_split=4),\n",
      "               DecisionTreeClassifier(min_samples_split=4),\n",
      "               DecisionTreeClassifier(min_samples_split=4),\n",
      "               DecisionTreeClassifier(min_samples_split=4)),\n",
      " 'fit_time': array([0.00596452, 0.00601482, 0.00482321, 0.0039897 , 0.00602317,\n",
      "       0.00498486, 0.0050211 , 0.00715113]),\n",
      " 'score_time': array([0.0040648 , 0.0039928 , 0.00199485, 0.0030489 , 0.00297999,\n",
      "       0.00312996, 0.00306582, 0.00401664]),\n",
      " 'test_score': array([0.91608392, 0.93661972, 0.88732394, 0.88732394, 0.93006993,\n",
      "       0.91549296, 0.92253521, 0.91549296]),\n",
      " 'train_score': array([0.99295775, 0.99765808, 0.99297424, 0.99297424, 0.99295775,\n",
      "       0.99531616, 0.99765808, 0.9882904 ])}\n",
      "\n",
      "Accuracy (Training): 0.99 (+/- 0.01)\n",
      "Accuracy (Testing):  0.91 (+/- 0.03)\n",
      "[[338  20]\n",
      " [ 27 184]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.94      0.93       358\n",
      "           1       0.90      0.87      0.89       211\n",
      "\n",
      "    accuracy                           0.92       569\n",
      "   macro avg       0.91      0.91      0.91       569\n",
      "weighted avg       0.92      0.92      0.92       569\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#rank 3\n",
    "dt2 = DecisionTreeClassifier(criterion='gini', max_depth=None, min_samples_split=4, splitter='best', random_state=None)\n",
    "\n",
    "rkf = RepeatedStratifiedKFold(n_splits=4,  n_repeats=2)\n",
    "scores = cross_validate(dt2, X, y, cv=rkf, return_train_score=True, return_estimator=True)\n",
    "y_pred = cross_val_predict(dt2, X, y, cv=6)\n",
    "\n",
    "pprint.pprint(scores)\n",
    "print()\n",
    "print(\"Accuracy (Training): %0.2f (+/- %0.2f)\" % (scores['train_score'].mean(), scores['train_score'].std() * 2))\n",
    "print(\"Accuracy (Testing):  %0.2f (+/- %0.2f)\" % (scores['test_score'].mean(), scores['test_score'].std() * 2))\n",
    "print(confusion_matrix(y, y_pred))\n",
    "report = classification_report(y, y_pred)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'estimator': (DecisionTreeClassifier(),\n",
      "               DecisionTreeClassifier(),\n",
      "               DecisionTreeClassifier(),\n",
      "               DecisionTreeClassifier(),\n",
      "               DecisionTreeClassifier(),\n",
      "               DecisionTreeClassifier(),\n",
      "               DecisionTreeClassifier(),\n",
      "               DecisionTreeClassifier()),\n",
      " 'fit_time': array([0.00595951, 0.00521755, 0.00396276, 0.00495768, 0.00401807,\n",
      "       0.00605679, 0.00801492, 0.00498605]),\n",
      " 'score_time': array([0.00299454, 0.0029912 , 0.0039773 , 0.00199437, 0.00301528,\n",
      "       0.00302052, 0.00399256, 0.00402355]),\n",
      " 'test_score': array([0.9020979 , 0.96478873, 0.91549296, 0.92957746, 0.94405594,\n",
      "       0.9084507 , 0.95774648, 0.9084507 ]),\n",
      " 'train_score': array([1., 1., 1., 1., 1., 1., 1., 1.])}\n",
      "\n",
      "Accuracy (Training): 1.00 (+/- 0.00)\n",
      "Accuracy (Testing):  0.93 (+/- 0.05)\n",
      "[[338  20]\n",
      " [ 23 188]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.94      0.94       358\n",
      "           1       0.90      0.89      0.90       211\n",
      "\n",
      "    accuracy                           0.92       569\n",
      "   macro avg       0.92      0.92      0.92       569\n",
      "weighted avg       0.92      0.92      0.92       569\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#rank 4\n",
    "dt3 = DecisionTreeClassifier(criterion='gini', max_depth=None, min_samples_split=2, splitter='best', random_state=None)\n",
    "\n",
    "rkf = RepeatedStratifiedKFold(n_splits=4,  n_repeats=2)\n",
    "scores = cross_validate(dt3, X, y, cv=rkf, return_train_score=True, return_estimator=True)\n",
    "y_pred = cross_val_predict(dt3, X, y, cv=6)\n",
    "\n",
    "pprint.pprint(scores)\n",
    "print()\n",
    "print(\"Accuracy (Training): %0.2f (+/- %0.2f)\" % (scores['train_score'].mean(), scores['train_score'].std() * 2))\n",
    "print(\"Accuracy (Testing):  %0.2f (+/- %0.2f)\" % (scores['test_score'].mean(), scores['test_score'].std() * 2))\n",
    "print(confusion_matrix(y, y_pred))\n",
    "report = classification_report(y, y_pred)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'estimator': (RandomForestClassifier(criterion='entropy', max_depth=5),\n",
      "               RandomForestClassifier(criterion='entropy', max_depth=5),\n",
      "               RandomForestClassifier(criterion='entropy', max_depth=5),\n",
      "               RandomForestClassifier(criterion='entropy', max_depth=5),\n",
      "               RandomForestClassifier(criterion='entropy', max_depth=5),\n",
      "               RandomForestClassifier(criterion='entropy', max_depth=5),\n",
      "               RandomForestClassifier(criterion='entropy', max_depth=5),\n",
      "               RandomForestClassifier(criterion='entropy', max_depth=5)),\n",
      " 'fit_time': array([0.26045775, 0.28418899, 0.26108003, 0.3148303 , 0.34177876,\n",
      "       0.35049009, 0.32511854, 0.29185295]),\n",
      " 'score_time': array([0.01998448, 0.01994705, 0.02500582, 0.01495433, 0.01400256,\n",
      "       0.02124858, 0.01621723, 0.01592278]),\n",
      " 'test_score': array([0.95104895, 0.93661972, 0.95774648, 0.90140845, 0.95804196,\n",
      "       0.9084507 , 0.95774648, 0.92957746]),\n",
      " 'train_score': array([0.98826291, 0.98360656, 0.9882904 , 0.9882904 , 0.98122066,\n",
      "       0.99297424, 0.98360656, 0.98360656])}\n",
      "\n",
      "Accuracy (Training): 0.99 (+/- 0.01)\n",
      "Accuracy (Testing):  0.94 (+/- 0.04)\n",
      "[[347  11]\n",
      " [ 21 190]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.97      0.96       358\n",
      "           1       0.95      0.90      0.92       211\n",
      "\n",
      "    accuracy                           0.94       569\n",
      "   macro avg       0.94      0.93      0.94       569\n",
      "weighted avg       0.94      0.94      0.94       569\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#creterion specified as in the other one should be gini by default\n",
    "rft3 = RandomForestClassifier(criterion='entropy', n_estimators=100, max_depth=5, random_state=None)\n",
    "\n",
    "rkf = RepeatedStratifiedKFold(n_splits=4,  n_repeats=2)\n",
    "scores = cross_validate(rft3, X, y, cv=rkf, return_train_score=True, return_estimator=True)\n",
    "y_pred = cross_val_predict(rft3, X, y, cv=6)\n",
    "\n",
    "pprint.pprint(scores)\n",
    "print()\n",
    "print(\"Accuracy (Training): %0.2f (+/- %0.2f)\" % (scores['train_score'].mean(), scores['train_score'].std() * 2))\n",
    "print(\"Accuracy (Testing):  %0.2f (+/- %0.2f)\" % (scores['test_score'].mean(), scores['test_score'].std() * 2))\n",
    "print(confusion_matrix(y, y_pred))\n",
    "report = classification_report(y, y_pred)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'estimator': (RandomForestClassifier(max_depth=15),\n",
      "               RandomForestClassifier(max_depth=15),\n",
      "               RandomForestClassifier(max_depth=15),\n",
      "               RandomForestClassifier(max_depth=15),\n",
      "               RandomForestClassifier(max_depth=15),\n",
      "               RandomForestClassifier(max_depth=15),\n",
      "               RandomForestClassifier(max_depth=15),\n",
      "               RandomForestClassifier(max_depth=15)),\n",
      " 'fit_time': array([0.29787898, 0.34595799, 0.29820919, 0.32582974, 0.26638055,\n",
      "       0.31043911, 0.28410602, 0.3074584 ]),\n",
      " 'score_time': array([0.02294254, 0.02293539, 0.0179503 , 0.01954937, 0.01841187,\n",
      "       0.02812076, 0.01797652, 0.02505493]),\n",
      " 'test_score': array([0.96503497, 0.92253521, 0.9084507 , 0.93661972, 0.95804196,\n",
      "       0.94366197, 0.8943662 , 0.95774648]),\n",
      " 'train_score': array([1., 1., 1., 1., 1., 1., 1., 1.])}\n",
      "\n",
      "Accuracy (Training): 1.00 (+/- 0.00)\n",
      "Accuracy (Testing):  0.94 (+/- 0.05)\n",
      "[[344  14]\n",
      " [ 19 192]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.96      0.95       358\n",
      "           1       0.93      0.91      0.92       211\n",
      "\n",
      "    accuracy                           0.94       569\n",
      "   macro avg       0.94      0.94      0.94       569\n",
      "weighted avg       0.94      0.94      0.94       569\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#creterion specified as in the other one should be gini by default\n",
    "rft3 = RandomForestClassifier(criterion='gini', n_estimators=100, max_depth=15, random_state=None)\n",
    "\n",
    "rkf = RepeatedStratifiedKFold(n_splits=4,  n_repeats=2)\n",
    "scores = cross_validate(rft3, X, y, cv=rkf, return_train_score=True, return_estimator=True)\n",
    "y_pred = cross_val_predict(rft3, X, y, cv=6)\n",
    "\n",
    "pprint.pprint(scores)\n",
    "print()\n",
    "print(\"Accuracy (Training): %0.2f (+/- %0.2f)\" % (scores['train_score'].mean(), scores['train_score'].std() * 2))\n",
    "print(\"Accuracy (Testing):  %0.2f (+/- %0.2f)\" % (scores['test_score'].mean(), scores['test_score'].std() * 2))\n",
    "print(confusion_matrix(y, y_pred))\n",
    "report = classification_report(y, y_pred)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DT VS RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done...\n",
      " - DT accuracy: 0.92 (+/- 0.00)\n",
      " - RF accuracy: 0.97 (+/- 0.00)\n"
     ]
    }
   ],
   "source": [
    "dt_acc = np.array([])\n",
    "rf_acc = np.array([])\n",
    "runs = 100\n",
    "\n",
    "for x in range(runs):\n",
    "    \n",
    "    # splitting the dataset each run, just to get more variation in the results for this example\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=None, stratify=df['Diagnosis'])\n",
    "    \n",
    "    # DT with default config\n",
    "    dt = DecisionTreeClassifier(random_state=None)\n",
    "    dt = dt.fit(X_train,y_train)\n",
    "    y_pred = dt.predict(X_test)\n",
    "    dt_accuracy = np.append(dt_acc, metrics.accuracy_score(y_test, y_pred))\n",
    "    \n",
    "    # Random Forest with 10 trees (and keeping other config as per default values)\n",
    "    rf = RandomForestClassifier(random_state=None)\n",
    "    rf = rf.fit(X_train,y_train)\n",
    "    y_pred = rf.predict(X_test)\n",
    "    rf_accuracy = np.append(rf_acc, metrics.accuracy_score(y_test, y_pred))\n",
    "\n",
    "print(\"Done...\")\n",
    "print(\" - DT accuracy: %0.2f (+/- %0.2f)\" % (dt_accuracy.mean(), dt_accuracy.std() * 2))\n",
    "print(\" - RF accuracy: %0.2f (+/- %0.2f)\" % (rf_accuracy.mean(), rf_accuracy.std() * 2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'estimator': (GaussianNB(),\n",
      "               GaussianNB(),\n",
      "               GaussianNB(),\n",
      "               GaussianNB(),\n",
      "               GaussianNB(),\n",
      "               GaussianNB(),\n",
      "               GaussianNB(),\n",
      "               GaussianNB(),\n",
      "               GaussianNB(),\n",
      "               GaussianNB(),\n",
      "               GaussianNB(),\n",
      "               GaussianNB(),\n",
      "               GaussianNB(),\n",
      "               GaussianNB(),\n",
      "               GaussianNB(),\n",
      "               GaussianNB(),\n",
      "               GaussianNB(),\n",
      "               GaussianNB(),\n",
      "               GaussianNB(),\n",
      "               GaussianNB()),\n",
      " 'fit_time': array([0.00718141, 0.0052309 , 0.00545096, 0.00299239, 0.00698233,\n",
      "       0.00419664, 0.00607252, 0.00660396, 0.00552034, 0.00291872,\n",
      "       0.00350595, 0.0040679 , 0.00395131, 0.00495505, 0.00398946,\n",
      "       0.00294876, 0.00408459, 0.0040226 , 0.00402761, 0.00598717]),\n",
      " 'score_time': array([0.00482655, 0.00500798, 0.00258493, 0.00299168, 0.00414538,\n",
      "       0.00299454, 0.00513577, 0.00397205, 0.00199556, 0.00299382,\n",
      "       0.0030303 , 0.00331926, 0.00299191, 0.0037384 , 0.00299692,\n",
      "       0.00199389, 0.0039916 , 0.00299287, 0.00395155, 0.00386572]),\n",
      " 'test_score': array([0.9020979 , 0.92957746, 0.88732394, 0.97183099, 0.93006993,\n",
      "       0.88732394, 0.90140845, 0.95070423, 0.9020979 , 0.92957746,\n",
      "       0.93661972, 0.92253521, 0.93006993, 0.91549296, 0.92253521,\n",
      "       0.91549296, 0.8951049 , 0.92957746, 0.92957746, 0.95070423]),\n",
      " 'train_score': array([0.92723005, 0.92505855, 0.93442623, 0.90866511, 0.92253521,\n",
      "       0.93208431, 0.92740047, 0.91334895, 0.93192488, 0.91803279,\n",
      "       0.91334895, 0.92271663, 0.92253521, 0.92740047, 0.92271663,\n",
      "       0.92740047, 0.9342723 , 0.92037471, 0.92271663, 0.91334895])}\n",
      "\n",
      "Accuracy (Training): 0.92 (+/- 0.01)\n",
      "Accuracy (Testing):  0.92 (+/- 0.04)\n",
      "[[340  18]\n",
      " [ 27 184]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.95      0.94       358\n",
      "           1       0.91      0.87      0.89       211\n",
      "\n",
      "    accuracy                           0.92       569\n",
      "   macro avg       0.92      0.91      0.91       569\n",
      "weighted avg       0.92      0.92      0.92       569\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#NB Model 1\n",
    "gaussianNB = GaussianNB()\n",
    "\n",
    "rkf = RepeatedStratifiedKFold(n_splits=4,  n_repeats=5)\n",
    "scores = cross_validate(gaussianNB, X, y, cv=rkf, return_train_score=True, return_estimator=True)\n",
    "y_pred = cross_val_predict(gaussianNB, X, y, cv=6)\n",
    "\n",
    "pprint.pprint(scores)\n",
    "print()\n",
    "print(\"Accuracy (Training): %0.2f (+/- %0.2f)\" % (scores['train_score'].mean(), scores['train_score'].std() * 2))\n",
    "print(\"Accuracy (Testing):  %0.2f (+/- %0.2f)\" % (scores['test_score'].mean(), scores['test_score'].std() * 2))\n",
    "print(confusion_matrix(y, y_pred))\n",
    "report = classification_report(y, y_pred)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'estimator': (MultinomialNB(),\n",
      "               MultinomialNB(),\n",
      "               MultinomialNB(),\n",
      "               MultinomialNB(),\n",
      "               MultinomialNB(),\n",
      "               MultinomialNB(),\n",
      "               MultinomialNB(),\n",
      "               MultinomialNB(),\n",
      "               MultinomialNB(),\n",
      "               MultinomialNB(),\n",
      "               MultinomialNB(),\n",
      "               MultinomialNB(),\n",
      "               MultinomialNB(),\n",
      "               MultinomialNB(),\n",
      "               MultinomialNB(),\n",
      "               MultinomialNB(),\n",
      "               MultinomialNB(),\n",
      "               MultinomialNB(),\n",
      "               MultinomialNB(),\n",
      "               MultinomialNB()),\n",
      " 'fit_time': array([0.00557232, 0.00555015, 0.00408149, 0.0048182 , 0.00398707,\n",
      "       0.00398779, 0.004987  , 0.00594354, 0.00604057, 0.00399494,\n",
      "       0.004987  , 0.00405002, 0.00398827, 0.00381804, 0.00598049,\n",
      "       0.00511122, 0.00475812, 0.00429702, 0.00552082, 0.00398827]),\n",
      " 'score_time': array([0.00253344, 0.0031774 , 0.00215054, 0.00299191, 0.00299239,\n",
      "       0.00299215, 0.00311923, 0.00313115, 0.00398803, 0.00299168,\n",
      "       0.00355625, 0.00349069, 0.00309706, 0.0032084 , 0.00499415,\n",
      "       0.00299215, 0.00279236, 0.00507712, 0.00349402, 0.00206017]),\n",
      " 'test_score': array([0.62937063, 0.62676056, 0.62676056, 0.63380282, 0.62937063,\n",
      "       0.62676056, 0.62676056, 0.63380282, 0.62937063, 0.62676056,\n",
      "       0.62676056, 0.63380282, 0.62937063, 0.62676056, 0.62676056,\n",
      "       0.63380282, 0.62937063, 0.62676056, 0.62676056, 0.63380282]),\n",
      " 'train_score': array([0.62910798, 0.62997658, 0.62997658, 0.62763466, 0.62910798,\n",
      "       0.62997658, 0.62997658, 0.62763466, 0.62910798, 0.62997658,\n",
      "       0.62997658, 0.62763466, 0.62910798, 0.62997658, 0.62997658,\n",
      "       0.62763466, 0.62910798, 0.62997658, 0.62997658, 0.62763466])}\n",
      "\n",
      "Accuracy (Training): 0.63 (+/- 0.00)\n",
      "Accuracy (Testing):  0.63 (+/- 0.01)\n",
      "[[358   0]\n",
      " [211   0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      1.00      0.77       358\n",
      "           1       0.00      0.00      0.00       211\n",
      "\n",
      "    accuracy                           0.63       569\n",
      "   macro avg       0.31      0.50      0.39       569\n",
      "weighted avg       0.40      0.63      0.49       569\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\sofik\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "#NB Model 2\n",
    "multinomialNB = MultinomialNB()\n",
    "\n",
    "rkf = RepeatedStratifiedKFold(n_splits=4,  n_repeats=5)\n",
    "scores = cross_validate(multinomialNB, X, y, cv=rkf, return_train_score=True, return_estimator=True)\n",
    "y_pred = cross_val_predict(multinomialNB, X, y, cv=6)\n",
    "\n",
    "pprint.pprint(scores)\n",
    "print()\n",
    "print(\"Accuracy (Training): %0.2f (+/- %0.2f)\" % (scores['train_score'].mean(), scores['train_score'].std() * 2))\n",
    "print(\"Accuracy (Testing):  %0.2f (+/- %0.2f)\" % (scores['test_score'].mean(), scores['test_score'].std() * 2))\n",
    "print(confusion_matrix(y, y_pred))\n",
    "report = classification_report(y, y_pred)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'estimator': (BernoulliNB(),\n",
      "               BernoulliNB(),\n",
      "               BernoulliNB(),\n",
      "               BernoulliNB(),\n",
      "               BernoulliNB(),\n",
      "               BernoulliNB(),\n",
      "               BernoulliNB(),\n",
      "               BernoulliNB(),\n",
      "               BernoulliNB(),\n",
      "               BernoulliNB(),\n",
      "               BernoulliNB(),\n",
      "               BernoulliNB(),\n",
      "               BernoulliNB(),\n",
      "               BernoulliNB(),\n",
      "               BernoulliNB(),\n",
      "               BernoulliNB(),\n",
      "               BernoulliNB(),\n",
      "               BernoulliNB(),\n",
      "               BernoulliNB(),\n",
      "               BernoulliNB()),\n",
      " 'fit_time': array([0.00494933, 0.00594473, 0.00556064, 0.0049715 , 0.00496817,\n",
      "       0.004076  , 0.00506234, 0.00702453, 0.00495195, 0.00519919,\n",
      "       0.00518751, 0.0040791 , 0.00508189, 0.00498796, 0.00498581,\n",
      "       0.00398898, 0.0039897 , 0.00303268, 0.00498533, 0.00402617]),\n",
      " 'score_time': array([0.00305557, 0.00398898, 0.00350881, 0.00395727, 0.00202346,\n",
      "       0.00307703, 0.00505066, 0.00405216, 0.00299954, 0.00298309,\n",
      "       0.00301027, 0.00301695, 0.00281501, 0.00299215, 0.00299168,\n",
      "       0.00299191, 0.00299168, 0.00295091, 0.00199604, 0.00204897]),\n",
      " 'test_score': array([0.62237762, 0.62676056, 0.61971831, 0.63380282, 0.62937063,\n",
      "       0.61971831, 0.62676056, 0.62676056, 0.62237762, 0.62676056,\n",
      "       0.62676056, 0.62676056, 0.62937063, 0.62676056, 0.61971831,\n",
      "       0.62676056, 0.62937063, 0.62676056, 0.61971831, 0.62676056]),\n",
      " 'train_score': array([0.62910798, 0.62997658, 0.62997658, 0.62763466, 0.62910798,\n",
      "       0.62997658, 0.62997658, 0.62763466, 0.62910798, 0.62997658,\n",
      "       0.62997658, 0.62763466, 0.62910798, 0.62997658, 0.62997658,\n",
      "       0.62763466, 0.62910798, 0.62997658, 0.62997658, 0.62763466])}\n",
      "\n",
      "Accuracy (Training): 0.63 (+/- 0.00)\n",
      "Accuracy (Testing):  0.63 (+/- 0.01)\n",
      "[[356   2]\n",
      " [211   0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.99      0.77       358\n",
      "           1       0.00      0.00      0.00       211\n",
      "\n",
      "    accuracy                           0.63       569\n",
      "   macro avg       0.31      0.50      0.38       569\n",
      "weighted avg       0.40      0.63      0.48       569\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#NB model 3\n",
    "bernoulliNB = BernoulliNB()\n",
    "rkf = RepeatedStratifiedKFold(n_splits=4,  n_repeats=5)\n",
    "scores = cross_validate(bernoulliNB, X, y, cv=rkf, return_train_score=True, return_estimator=True)\n",
    "y_pred = cross_val_predict(bernoulliNB, X, y, cv=6)\n",
    "\n",
    "pprint.pprint(scores)\n",
    "print()\n",
    "print(\"Accuracy (Training): %0.2f (+/- %0.2f)\" % (scores['train_score'].mean(), scores['train_score'].std() * 2))\n",
    "print(\"Accuracy (Testing):  %0.2f (+/- %0.2f)\" % (scores['test_score'].mean(), scores['test_score'].std() * 2))\n",
    "print(confusion_matrix(y, y_pred))\n",
    "report = classification_report(y, y_pred)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "#All 3 NB comparison "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Gaussian accuracy:    0.92 (+/- 0.05)\n",
      " Multinomial accuracy: 0.63 (+/- 0.00)\n",
      " Bernoulli accuracy:   0.63 (+/- 0.01)\n"
     ]
    }
   ],
   "source": [
    "gaussian = np.array([])\n",
    "muiltinomial = np.array([])\n",
    "bernoulli = np.array([])\n",
    "\n",
    "runs = 100\n",
    "for x in range(runs):\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=None, stratify=df['Diagnosis'])\n",
    "    \n",
    "    # Gaussian NB\n",
    "    gaussianNB = GaussianNB()\n",
    "    gaussianNB = gaussianNB.fit(X_train,y_train)\n",
    "    y_pred = gaussianNB.predict(X_test)\n",
    "    gaussian = np.append(gaussian, metrics.accuracy_score(y_test, y_pred))\n",
    "    \n",
    "    # Multinomial NB\n",
    "    multinomialNB = MultinomialNB()\n",
    "    multinomialNB = multinomialNB.fit(X_train,y_train)\n",
    "    y_pred = multinomialNB.predict(X_test)\n",
    "    muiltinomial = np.append(muiltinomial, metrics.accuracy_score(y_test, y_pred))\n",
    "    \n",
    "    # Bernoulli NB\n",
    "    bernoulliNB = BernoulliNB()\n",
    "    bernoulliNB = bernoulliNB.fit(X_train,y_train)\n",
    "    y_pred = bernoulliNB.predict(X_test)\n",
    "    bernoulli = np.append(bernoulli, metrics.accuracy_score(y_test, y_pred))\n",
    "\n",
    "\n",
    "print(\" Gaussian accuracy:    %0.2f (+/- %0.2f)\" % (gaussian.mean(), gaussian.std() * 2))\n",
    "print(\" Multinomial accuracy: %0.2f (+/- %0.2f)\" % (muiltinomial.mean(), muiltinomial.std() * 2))\n",
    "print(\" Bernoulli accuracy:   %0.2f (+/- %0.2f)\" % (bernoulli.mean(), bernoulli.std() * 2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
